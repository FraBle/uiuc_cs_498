{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "OUTPUT_FOLDER = Path('.') / 'Output' / '2019-04-26'\n",
    "DATA_SETS_FOLDER = Path('.') / '.datasets'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/bear-mbp/Library/Mobile Documents/com~apple~CloudDocs/Python/amzn_reviews_ds.csv')\n",
    "df = pd.read_csv(OUTPUT_FOLDER / 'amzn_reviews_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['product_title', 'product_category'], inplace=True, keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df.product_category == 'Video_Games') & (df.percent_rank == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cnt_log'] = np.log(df.cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[[\n",
    "    'product_category',\n",
    "    'cnt', \n",
    "    'helpful_votes_cnt',\n",
    "    'total_votes_cnt',\n",
    "    'verified_purchase_cnt',\n",
    "    'vine_cnt',\n",
    "    'star_rating_mean',\n",
    "    'helpful_votes_mean',\n",
    "    'total_votes_mean',\n",
    "    'star_rating_with_verified_purchase_mean',\n",
    "    'star_rating_with_vine_mean',\n",
    "    'star_rating_with_votes_mean',\n",
    "    'star_rating_helpful_votes_weighted_mean',\n",
    "    'helpful_votes_ratio',\n",
    "    'verified_purchase_ratio',\n",
    "    'vine_ratio',\n",
    "    'cnt_log'\n",
    "]].isnull().describe()\n",
    "\n",
    "df1.loc[['count', 'freq'],:].sum() - 11026.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target = ['percent_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesRegressor(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "training_ds = df[df.cnt >= 20.]\n",
    "training_ds.reset_index(inplace=True, drop=True)\n",
    "training_ds.fillna(0, inplace=True)\n",
    "\n",
    "# scale input variables\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(training_ds)\n",
    "# X = scaler.transform(training_ds[training_features])\n",
    "training_features = [\n",
    "    'product_category',\n",
    "    'cnt', \n",
    "    'helpful_votes_cnt',\n",
    "    'total_votes_cnt',\n",
    "    'verified_purchase_cnt',\n",
    "    'vine_cnt',\n",
    "    'star_rating_mean',\n",
    "    'helpful_votes_mean',\n",
    "    'total_votes_mean',\n",
    "    'star_rating_with_verified_purchase_mean',\n",
    "    'star_rating_with_vine_mean',\n",
    "    'star_rating_with_votes_mean',\n",
    "    'star_rating_helpful_votes_weighted_mean',\n",
    "    'helpful_votes_ratio',\n",
    "    'verified_purchase_ratio',\n",
    "    'vine_ratio',\n",
    "    'cnt_log'\n",
    "]\n",
    "\n",
    "X = training_ds[training_features]\n",
    "le = LabelEncoder()\n",
    "le.fit(X['product_category'])\n",
    "X['product_category'] = le.transform(X['product_category'])\n",
    "y = training_ds[training_target]\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f, training_features[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_features = ['cnt_log', 'star_rating_mean', 'verified_purchase_ratio', 'total_votes_mean']\n",
    "training_features = ['cnt_log', 'star_rating_mean', 'verified_purchase_ratio', 'total_votes_mean',\n",
    "                     'product_category', 'helpful_votes_ratio']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find significant count cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores = []\n",
    "test_scores = []\n",
    "features_used = []\n",
    "exclude_cnts = range(1, 51)\n",
    "\n",
    "for exclude_cnt in exclude_cnts: \n",
    "    # select feature and target columns\n",
    "#     training_features = ['cnt_log', 'star_rating_mean', 'verified_purchase_ratio', 'total_votes_mean']\n",
    "#     training_target = ['percent_rank']\n",
    "    training_ds = df[df.cnt >= exclude_cnt]\n",
    "    training_ds.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    if 'product_category' in training_ds:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(training_ds['product_category'])\n",
    "        training_ds['product_category'] = le.transform(training_ds['product_category'])\n",
    "        \n",
    "    training_ds.fillna(0, inplace=True)\n",
    "    \n",
    "    # scale input variables\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(training_ds[training_features])\n",
    "    X = scaler.transform(training_ds[training_features])\n",
    "    y = training_ds[training_target]\n",
    "    \n",
    "#     poly = PolynomialFeatures(2)\n",
    "#     X = poly.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # train a model to learn from the dataset\n",
    "    clf = linear_model.Lasso(alpha=0.01)\n",
    "    clf.fit(X_train,y_train)\n",
    "    train_score=clf.score(X_train,y_train)\n",
    "    test_score=clf.score(X_test,y_test)\n",
    "    coeff_used = np.sum(clf.coef_!=0)\n",
    "    \n",
    "    training_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    features_used.append(coeff_used)\n",
    "    # # print best features\n",
    "    # print(\"\\ntop features:\")\n",
    "    # for coef in reversed(sorted(clf.coef_)):\n",
    "    #     if coef > 0:\n",
    "    #         coef_index = list(clf.coef_).index(coef)\n",
    "    #         print(\"{} ({})\".format(training_features[coef_index], coef))\n",
    "    \n",
    "plt.plot(exclude_cnts, np.clip(training_scores, 0, 1.))\n",
    "plt.plot(exclude_cnts, np.clip(test_scores, 0, 1.))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_cut_off = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using polynomial features and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select feature and target columns\n",
    "# training_features = ['cnt_log', 'star_rating_mean', 'verified_purchase_cnt', 'helpful_votes_mean', 'total_votes_mean']\n",
    "training_target = ['percent_rank']\n",
    "training_ds = df[df.cnt >= significant_cut_off]\n",
    "training_ds = pd.concat([training_ds[training_ds['product_category'] != 'Video_DVD'],\n",
    "                         training_ds[training_ds['product_category'] == 'Video_DVD'].sample(300)])\n",
    "training_ds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "if 'product_category' in training_ds:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(training_ds['product_category'])\n",
    "    training_ds['product_category'] = le.transform(training_ds['product_category'])\n",
    "\n",
    "# scale input variables\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(training_ds[training_features])\n",
    "X = scaler.transform(training_ds[training_features])\n",
    "y = training_ds[training_target]\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train a model to learn from the dataset\n",
    "clf = linear_model.Lasso(alpha=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "train_score=clf.score(X_train,y_train)\n",
    "test_score=clf.score(X_test,y_test)\n",
    "coeff_used = np.sum(clf.coef_!=0)\n",
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "\n",
    "# # print best features\n",
    "# print(\"\\ntop features:\")\n",
    "# for coef in reversed(sorted(clf.coef_)):\n",
    "#     if coef > 0:\n",
    "#         coef_index = list(clf.coef_).index(coef)\n",
    "#         print(\"{} ({})\".format(training_features[coef_index], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Predictions\n",
    "training_pred_values = np.clip(clf.predict(X_train), 0., 1.)\n",
    "training_pred_values = np.array(list(zip(training_pred_values, y_train.as_matrix().reshape(-1,))))\n",
    "print('training_pred')\n",
    "print(training_pred_values[:10])\n",
    "\n",
    "test_pred_values = np.clip(clf.predict(X_test), 0., 1.)\n",
    "test_pred_values = np.array(list(zip(test_pred_values, y_test.as_matrix().reshape(-1,))))\n",
    "print('test_pred')\n",
    "print(test_pred_values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training')\n",
    "X_train\n",
    "plt.scatter(training_pred_values[:,0], training_pred_values[:,1])\n",
    "plt.plot([0.,1.], [0.,1.], alpha=.5)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlim([0., 1.])\n",
    "plt.ylim([0., 1.])\n",
    "plt.show()\n",
    "\n",
    "print('test')\n",
    "plt.scatter(test_pred_values[:,0], test_pred_values[:,1])\n",
    "plt.plot([0.,1.], [0.,1.], alpha=.5)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlim([0., 1.])\n",
    "plt.ylim([0., 1.])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_metrics = explained_variance_score, mean_absolute_error, r2_score\n",
    "\n",
    "for metric in regression_metrics:\n",
    "    print(metric)    \n",
    "    print('train', metric(y_train, training_pred_values[:,0]))\n",
    "    print('test', metric(y_test, test_pred_values[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#X_train, X_test, y_train, y_test\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "print('LinearRegression:', lin_reg.score(X_test, y_test))\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Ridge:', ridge.score(X_test, y_test))\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "print('Lasso:', lasso.score(X_test, y_test))\n",
    "\n",
    "elastic_net = linear_model.ElasticNet(alpha=0.1)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "print('ElasticNet:', elastic_net.score(X_test, y_test))\n",
    "\n",
    "lasso_lars = linear_model.LassoLars()\n",
    "lasso_lars.fit(X_train, y_train)\n",
    "print('LassoLars:', lasso_lars.score(X_test, y_test))\n",
    "\n",
    "bayesian_ridge = linear_model.BayesianRidge()\n",
    "bayesian_ridge.fit(X_train, y_train)\n",
    "print('BayesianRidge:', bayesian_ridge.score(X_test, y_test))\n",
    "\n",
    "svc = svm.SVR(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "print('SVR:', svc.score(X_test, y_test))\n",
    "\n",
    "dtr = tree.DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)\n",
    "print('DTR:', dtr.score(X_test, y_test))\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "gbr.fit(X_train, y_train)\n",
    "print('GBR:', gbr.score(X_test, y_test))\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "mlp.fit(X_train, y_train)\n",
    "print('MLP:', mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare separating categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preds = np.clip(clf.predict(X), 0, 1.)\n",
    "X_pred_values = np.array(list(zip(y.values.reshape(-1), X_preds)))\n",
    "norms = np.abs(X_pred_values[:,0] - X_pred_values[:,1])\n",
    "norms_args = np.argsort(norms)\n",
    "\n",
    "training_ds_pred = training_ds.copy()\n",
    "training_ds_pred['pred'] = X_preds\n",
    "training_ds_pred.iloc[norms_args[-20:]]\n",
    "# training_ds_pred.iloc[norms_args[:5]]\n",
    "# [x for _,x in sorted(zip(norms,training_pred_values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Data TODOs:\n",
    "# Remove Critic_Score == 0 from product_category Video_Games\n",
    "# Add helpful_votes_count and total_votes_count\n",
    "# Add helpful_votes to total_votes ratio \n",
    "# Add helpful_votes to total_votes ratio multiplied by star_rating mean\n",
    "\n",
    "# Verified purchased ratio\n",
    "# Verified purchased star_rating non-zero mean\n",
    "\n",
    "# Vine ratio\n",
    "# Vine star_rating non-zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('/private/tmp/amazon_reviews_us_Music_v1_00.tsv', sep='/t', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_SETS_FOLDER / 'amazon_reviews_us_Mobile_Electronics_v1_00.tsv', delimiter='\\t',\n",
    "                 error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds[training_ds.product_category == 'Video_Games'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds[training_ds.product_category == 'Books'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds[training_ds.product_category == 'Video_DVD'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
